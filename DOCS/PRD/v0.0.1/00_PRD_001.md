# Product Requirements Document: Hyperprompt Compiler v0.1

**Document Version:** 0.0.1
**Date:** November 25, 2025
**Author:** Egor Merkushev
**Status:** Draft for Implementation

-----

## 1. Executive Summary

### 1.1 Objective

This document specifies the requirements for Hyperprompt Compiler v0.1, a cross-platform command-line application written in Swift that compiles Hypercode source files (.hc) into unified Markdown documents. The compiler implements a minimal viable subset of the Hyperprompt Framework specification, focusing exclusively on hierarchical document composition through file embedding.

### 1.2 Primary Deliverables

The project shall deliver a single executable binary named `hyperprompt` that accepts Hypercode source files as input and produces compiled Markdown documents as output. The compiler shall also generate a manifest file documenting all source files consumed during compilation, enabling provenance tracking and reproducibility verification.

### 1.3 Success Criteria

The implementation shall be considered successful when the compiler can parse valid Hypercode syntax with indentation-based hierarchy, resolve file references to both Markdown (.md) and Hypercode (.hc) files, recursively compile nested Hypercode imports while detecting and rejecting circular dependencies, adjust heading levels in embedded content according to tree depth, operate in both strict and lenient modes for reference resolution, generate SHA256-based manifests for all consumed sources, and execute correctly on macOS, Linux, and Windows platforms.

### 1.4 Constraints and Assumptions

The implementation assumes that all input files use UTF-8 encoding without byte order marks. The compiler does not implement Hypercode Cascade Sheets (.hcs) configuration in this version. Variable interpolation and TaskRecord extraction are explicitly out of scope. The compiler operates on local filesystem resources only, with no network access required or permitted. Maximum supported tree depth shall be 10 levels to prevent stack overflow in recursive resolution.

-----

## 2. Terminology

**Hypercode (.hc):** A declarative, indentation-based source file format defining hierarchical document structure through quoted string literals.

**Literal:** A sequence of characters enclosed in double quotation marks within a Hypercode file. A literal represents either inline text content or a file path reference.

**File Reference:** A literal whose content corresponds to an existing file path in the filesystem. File references are resolved and their content is embedded during compilation.

**Primitive:** A Markdown file (.md) containing atomic content intended for embedding into compiled output.

**Node:** A single literal at a specific depth in the Hypercode tree structure. Each node may have child nodes at greater indentation depth.

**Tree Depth:** The nesting level of a node, determined by its indentation. Root-level nodes have depth 0.

**Heading Shift:** The transformation applied to Markdown headings in embedded content, offsetting heading levels by the embedding node's tree depth plus one.

**Manifest:** A JSON document recording metadata about all source files consumed during compilation, including file paths, SHA256 hashes, and byte sizes.

**Strict Mode:** A compilation mode where unresolved file references cause compilation failure.

**Lenient Mode:** A compilation mode where unresolved file references are treated as inline text literals.

-----

## 3. Functional Requirements

### 3.1 Input Processing

#### 3.1.1 Hypercode Parsing

The compiler shall accept a single Hypercode file as its primary input. The parser shall recognize lines matching the pattern of optional leading indentation followed by a quoted string literal. Each indentation level shall consist of exactly four space characters. Tab characters in indentation shall be rejected with a diagnostic error indicating the line number and suggesting conversion to spaces.

The parser shall extract the content between the first and last double quotation mark on each non-empty, non-comment line. Lines beginning with the hash character (#) after optional indentation shall be treated as comments and ignored. Empty lines shall be preserved in the AST as structural separators but shall not generate output.

#### 3.1.2 Tree Construction

The parser shall construct an abstract syntax tree where each node contains the literal content, the computed depth based on indentation, an ordered list of child nodes, and the source location comprising file path and line number. Depth shall be calculated as the count of leading spaces divided by four, using integer division. Nodes shall be assigned as children to the nearest preceding node with strictly smaller depth.

#### 3.1.3 Reference Resolution

For each node in the AST, the compiler shall determine whether the literal content represents a file reference by checking whether a file exists at the path formed by joining the compilation root directory with the literal content. If the file exists and has the extension `.md`, the compiler shall read its content for embedding as Markdown. If the file exists and has the extension `.hc`, the compiler shall recursively parse and compile it, embedding the resulting Markdown. If the file does not exist and strict mode is enabled, the compiler shall emit an error and terminate. If the file does not exist and lenient mode is enabled, the compiler shall treat the literal as inline text.

#### 3.1.4 Circular Dependency Detection

The compiler shall maintain a stack of file paths currently being processed during recursive resolution. Before processing any file reference, the compiler shall check whether the target path appears in the current stack. If a cycle is detected, the compiler shall emit an error message identifying the cycle path and terminate with a non-zero exit code.

### 3.2 Output Generation

#### 3.2.1 Markdown Emission

The compiler shall produce a single Markdown document as its primary output. For each node in the AST, the output shall consist of a heading derived from the node content or embedded file, followed by the body content if the node references a file.

Heading level shall be calculated as tree depth plus one, yielding H1 for depth 0, H2 for depth 1, and so forth. For depths exceeding 5, the compiler shall use H6 headings with a breadcrumb path prefix indicating the full hierarchy.

#### 3.2.2 Heading Adjustment in Embedded Content

When embedding Markdown content from referenced files, the compiler shall adjust all heading levels within that content. The adjustment offset shall equal the embedding node's depth plus one. A heading written as H1 in the source file, when embedded at depth 1, shall become H3 in the output. The compiler shall parse headings using both ATX style (hash prefixes) and Setext style (underline), adjusting both forms consistently.

If adjusted heading level would exceed 6, the compiler shall cap at H6 and prepend a hierarchical path indicator to the heading text.

#### 3.2.3 Content Separator Insertion

The compiler shall insert a single blank line between the output of consecutive nodes at the same depth. The compiler shall insert two blank lines before any H1 or H2 heading except at the document start.

### 3.3 Manifest Generation

#### 3.3.1 Manifest Content

The compiler shall produce a JSON manifest file containing a timestamp in ISO 8601 format recording when compilation completed, the compiler version string, a sources array listing every file consumed during compilation, and a root field identifying the primary input file.

Each entry in the sources array shall include the path relative to the compilation root, the SHA256 hash of file content encoded as lowercase hexadecimal, the file size in bytes, and the type indicating either "hypercode" or "markdown".

#### 3.3.2 Manifest Output Path

By default, the manifest shall be written to the same directory as the primary output file, with the same base name and the extension `.manifest.json`. The user may override this path via command-line option.

### 3.4 Command-Line Interface

#### 3.4.1 Required Arguments

The compiler shall require a single positional argument specifying the path to the input Hypercode file.

#### 3.4.2 Optional Arguments

The compiler shall accept the following optional arguments. The `--output` or `-o` option specifies the output Markdown file path, defaulting to the input file name with extension changed to `.md`. The `--manifest` or `-m` option specifies the manifest file path, defaulting to output path with extension `.manifest.json`. The `--root` or `-r` option specifies the root directory for resolving relative file references, defaulting to the input file's parent directory. The `--strict` flag enables strict mode where missing file references cause errors, and this is the default behavior. The `--lenient` flag enables lenient mode where missing file references become inline text. The `--stats` flag prints compilation statistics to standard error upon completion. The `--dry-run` flag validates input and reports errors without writing output files. The `--verbose` or `-v` flag enables detailed logging of resolution steps to standard error. The `--help` or `-h` flag displays usage information and exits. The `--version` flag displays the compiler version and exits.

#### 3.4.3 Exit Codes

The compiler shall exit with code 0 on successful compilation, code 1 on input/output errors such as file not found or permission denied, code 2 on syntax errors in Hypercode source, code 3 on resolution errors such as circular dependencies or missing references in strict mode, and code 4 on internal errors.

### 3.5 Statistics Output

When the `--stats` flag is provided, the compiler shall output to standard error the total number of source files processed, the sum of input bytes across all sources, the output file size in bytes, the count of Hypercode files processed, the count of Markdown files embedded, the maximum tree depth encountered, and the elapsed compilation time in milliseconds.

-----

## 4. Non-Functional Requirements

### 4.1 Performance

The compiler shall process input files at a rate of no less than 10 megabytes per second on commodity hardware, defined as a system with a 2 GHz dual-core processor and solid-state storage. Compilation of a 1000-node tree with average file size of 4 kilobytes shall complete within 5 seconds. Memory consumption shall not exceed 10 times the total size of all input files, providing headroom for AST structures and string processing.

### 4.2 Reliability

The compiler shall not crash or produce undefined behavior on any syntactically valid or invalid input. All error conditions shall produce diagnostic messages identifying the source location and nature of the problem. The compiler shall be idempotent, meaning that recompiling the same inputs shall produce byte-identical outputs.

### 4.3 Portability

The compiled binary shall execute without modification on macOS 12 and later on both Intel and Apple Silicon architectures, on Ubuntu 20.04 and later on x86_64 and arm64 architectures, and on Windows 10 and later on x86_64 architecture. The compiler shall handle platform-specific path separators correctly, accepting forward slashes in Hypercode source regardless of platform and converting as necessary for filesystem access.

### 4.4 Maintainability

The codebase shall be organized into distinct modules for parsing, AST representation, resolution, emission, and CLI handling. Each module shall have corresponding unit tests achieving no less than 80% line coverage. Public APIs shall include documentation comments in Swift's standard format.

### 4.5 Security

The compiler shall not execute any code or scripts found in input files. File access shall be restricted to paths within or below the specified root directory; attempts to reference paths containing `..` that would escape the root shall be rejected in strict mode. The compiler shall not follow symbolic links that point outside the root directory.

-----

## 5. Hypercode Language Specification

### 5.1 Lexical Structure

A Hypercode source file consists of a sequence of lines. Each line is classified as blank, comment, or node. Blank lines contain only space characters (tab characters are not permitted). Comment lines begin with optional indentation (zero or more groups of four spaces) followed by the hash character. Node lines contain optional leading spaces for indentation, an opening double quotation mark, literal content, and a closing double quotation mark.

### 5.2 Grammar

The formal grammar in extended Backus-Naur form is as follows:

```
program     = { line } ;
line        = blank | comment | node ;
blank       = { space }, newline ;
comment     = { indent }, "#", { any-char }, newline ;
node        = indent, '"', content, '"', newline ;
indent      = { "    " } ;
content     = { any-char - '"' } ;
space       = U+0020 ;
newline     = U+000A | U+000D, U+000A ;
any-char    = ? any Unicode scalar value ? ;
```

### 5.3 Escape Sequences

Within literal content, the following escape sequences shall be recognized: backslash followed by double quote produces a literal double quote character, backslash followed by backslash produces a literal backslash character, and backslash followed by n produces a newline character. Any other character following a backslash shall be treated as an error in strict mode or passed through literally in lenient mode.

### 5.4 Semantic Rules

Each node's depth is computed as the number of leading spaces divided by four. A node at depth N becomes a child of the most recently encountered node at depth N-1. Nodes at depth 0 are root nodes. Multiple root nodes are permitted, forming a forest that is processed sequentially.

The content of each node is interpreted according to resolution rules. If the content matches an existing file path relative to the root directory, it is treated as a file reference. Otherwise, it is treated as an inline text literal. File references to paths with extension `.hc` are compiled recursively. File references to paths with extension `.md` have their content embedded with heading adjustment. File references to paths with other extensions are embedded as fenced code blocks with language hint derived from the extension.

-----

## 6. Architecture

### 6.1 Module Structure

The compiler shall be organized into six primary modules.

The Core module defines fundamental types including SourceLocation, Diagnostic, and CompilerError. It provides utilities for file system access abstraction and string manipulation helpers.

The Parser module implements the Lexer type that performs line-by-line tokenization, the Parser type that constructs the AST from token stream, and the AST types including Node, NodeKind, and Program.

The Resolver module implements the ReferenceResolver type that determines reference types for literals, the DependencyTracker type that detects circular dependencies, and the FileLoader type that reads and caches file contents.

The Emitter module implements the MarkdownEmitter type that generates output from resolved AST, the HeadingAdjuster type that transforms heading levels in embedded content, and the ManifestGenerator type that produces provenance documentation.

The CLI module implements argument parsing using swift-argument-parser, the CompilerDriver type that orchestrates the compilation pipeline, and the DiagnosticPrinter type that formats error messages for terminal output.

The Statistics module implements the StatsCollector type that gathers metrics during compilation and the StatsReporter type that formats statistics for output.

### 6.2 Data Flow

The compilation pipeline proceeds through the following stages. The CLI module parses command-line arguments and validates paths. The Parser module reads the input file, tokenizes lines, and constructs the AST. The Resolver module traverses the AST and resolves each node's content, recursively processing nested Hypercode files and loading Markdown content. The Emitter module traverses the resolved AST and generates Markdown output, adjusting heading levels and inserting separators. The ManifestGenerator module collects metadata from all processed files and produces JSON output. The CLI module writes output files and reports statistics if requested.

### 6.3 Error Handling Strategy

All errors shall be represented as values conforming to the CompilerError protocol, which requires a diagnostic message, an optional source location, and an error category for exit code determination. Functions that may fail shall return Result types rather than throwing exceptions, enabling explicit error propagation and aggregation. The compiler shall attempt to report multiple errors per compilation run where possible, rather than stopping at the first error.

-----

## 7. Implementation Plan

### 7.1 Phase 1: Foundation

**Duration Estimate:** 3 days

This phase establishes the project structure and implements core parsing functionality.

Task 1.1 involves project initialization, which includes creating the Swift package with appropriate directory structure, configuring the Package.swift with dependencies on swift-argument-parser and swift-crypto, establishing the module boundaries, and setting up the test target structure. The priority is high, the effort estimate is 2 hours, and the acceptance criteria is that `swift build` completes without errors and `swift test` runs an empty test suite.

Task 1.2 involves implementing core types, which includes defining SourceLocation as a struct with file path and line number, defining CompilerError as an enum with associated diagnostic information, implementing the FileSystem protocol for abstracting file operations, and creating a MockFileSystem for testing. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that unit tests verify all error cases produce appropriate diagnostics.

Task 1.3 involves implementing the lexer, which includes implementing line-by-line tokenization, recognizing blank lines, comment lines, and node lines, extracting indentation level and literal content, and handling escape sequences within literals. The priority is high, the effort estimate is 6 hours, and the acceptance criteria is that lexer correctly tokenizes the provided test corpus of 20 sample files.

Task 1.4 involves implementing the parser, which includes implementing AST node types, building tree structure from token stream based on indentation, computing depth and parent-child relationships, and reporting syntax errors with source locations. The priority is high, the effort estimate is 8 hours, and the acceptance criteria is that parser produces correct AST for all valid test inputs and reports meaningful errors for all invalid inputs.

### 7.2 Phase 2: Resolution

**Duration Estimate:** 4 days

This phase implements file reference resolution and circular dependency detection.

Task 2.1 involves implementing the reference resolver, which includes implementing file existence checking against the root directory, classifying literals as file references or inline text, handling `.md` and `.hc` extensions differently, and implementing strict and lenient mode behaviors. The priority is high, the effort estimate is 6 hours, and the acceptance criteria is that resolver correctly classifies all reference types in the test corpus.

Task 2.2 involves implementing the dependency tracker, which includes implementing the visitation stack for cycle detection, detecting direct and transitive circular dependencies, producing clear cycle path descriptions in error messages, and optimizing for deep trees with memoization. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that circular dependencies are detected and reported with full cycle paths.

Task 2.3 involves implementing the file loader, which includes implementing file content reading with encoding detection, caching loaded content to avoid redundant reads, computing SHA256 hashes during loading, and collecting file metadata for manifest generation. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that file content is correctly loaded and cached with accurate hashes.

Task 2.4 involves implementing recursive compilation, which includes implementing recursive invocation of parser and resolver for `.hc` files, merging child ASTs into parent tree at correct depth, propagating errors from nested compilations, and maintaining consistent source location tracking across files. The priority is high, the effort estimate is 8 hours, and the acceptance criteria is that nested `.hc` files are correctly compiled and embedded.

### 7.3 Phase 3: Emission

**Duration Estimate:** 3 days

This phase implements Markdown output generation.

Task 3.1 involves implementing the heading adjuster, which includes parsing ATX-style headings with hash prefixes, parsing Setext-style headings with underlines, computing adjusted heading level based on embedding depth, handling overflow beyond H6 with path prefixes, and preserving heading attributes and trailing content. The priority is high, the effort estimate is 6 hours, and the acceptance criteria is that all heading styles are correctly adjusted in test corpus.

Task 3.2 involves implementing the Markdown emitter, which includes implementing tree traversal for output generation, generating headings from node content or file names, embedding file content with adjusted headings, inserting appropriate separators between sections, and handling inline text literals as body content. The priority is high, the effort estimate is 8 hours, and the acceptance criteria is that emitter produces valid Markdown matching expected output for all test cases.

Task 3.3 involves implementing the manifest generator, which includes collecting metadata from all processed files, generating ISO 8601 timestamp, formatting JSON output with consistent key ordering, and writing manifest to specified path. The priority is medium, the effort estimate is 3 hours, and the acceptance criteria is that manifest contains accurate metadata for all source files.

### 7.4 Phase 4: CLI and Integration

**Duration Estimate:** 3 days

This phase implements the command-line interface and integrates all components.

Task 4.1 involves implementing argument parsing, which includes defining command structure with swift-argument-parser, implementing all specified flags and options, validating argument combinations, and generating help text. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that all documented arguments are recognized and validated.

Task 4.2 involves implementing the compiler driver, which includes orchestrating the full compilation pipeline, implementing dry-run mode, implementing verbose logging, and handling interruption signals gracefully. The priority is high, the effort estimate is 6 hours, and the acceptance criteria is that end-to-end compilation succeeds for all valid test inputs.

Task 4.3 involves implementing the diagnostic printer, which includes formatting error messages with source context, colorizing output for terminal display, supporting plain text output for non-terminal destinations, and aggregating multiple errors when possible. The priority is medium, the effort estimate is 4 hours, and the acceptance criteria is that error messages clearly identify problem location and nature.

Task 4.4 involves implementing the statistics reporter, which includes collecting metrics during compilation, formatting statistics output, calculating derived metrics such as compression ratio and processing rate, and integrating with verbose mode output. The priority is low, the effort estimate is 3 hours, and the acceptance criteria is that statistics output includes all specified metrics.

### 7.5 Phase 5: Testing and Documentation

**Duration Estimate:** 2 days

This phase completes testing coverage and produces documentation.

Task 5.1 involves implementing integration tests, which includes creating a test corpus with representative Hypercode files, implementing golden-file tests comparing output to expected results, testing error conditions and edge cases, and achieving 80% code coverage threshold. The priority is high, the effort estimate is 8 hours, and the acceptance criteria is that all integration tests pass and coverage threshold is met.

Task 5.2 involves cross-platform testing, which includes testing on macOS with both Intel and Apple Silicon, testing on Ubuntu 22.04, testing on Windows 10 with WSL and native, and documenting any platform-specific behaviors. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that identical inputs produce identical outputs on all platforms.

Task 5.3 involves producing documentation, which includes writing README with installation and usage instructions, documenting the Hypercode language specification, providing example files demonstrating all features, and generating API documentation from source comments. The priority is medium, the effort estimate is 4 hours, and the acceptance criteria is that documentation is complete and accurate.

-----

## 8. Test Corpus Specification

### 8.1 Valid Input Tests

The test corpus shall include the following valid input scenarios.

Test V01 covers a single root node with inline text, verifying basic parsing and emission. Test V02 covers multiple root nodes forming a document forest. Test V03 covers a nested hierarchy three levels deep with inline text. Test V04 covers a single Markdown file reference at root level. Test V05 covers nested Markdown file references at multiple depths. Test V06 covers a single Hypercode file reference. Test V07 covers nested Hypercode file references three levels deep. Test V08 covers mixed inline text and file references at the same depth. Test V09 covers a file reference to Markdown containing headings H1 through H4. Test V10 covers a file reference to Markdown containing Setext-style headings. Test V11 covers escape sequences for quotes and backslashes in literals. Test V12 covers comment lines interspersed with nodes. Test V13 covers blank lines between node groups. Test V14 covers the maximum supported depth of 10 levels. Test V15 covers Unicode content in literals and embedded files. Test V16 covers a file reference to a non-Markdown, non-Hypercode file such as `.swift` embedded as a code block.

### 8.2 Invalid Input Tests

The test corpus shall include the following invalid input scenarios.

Test I01 covers tab characters in indentation, which should produce a syntax error. Test I02 covers misaligned indentation not divisible by four. Test I03 covers an unclosed quotation mark at end of file. Test I04 covers a missing file reference in strict mode. Test I05 covers a direct circular dependency where A references A. Test I06 covers an indirect circular dependency where A references B, B references A. Test I07 covers a depth exceeding maximum of 10 levels. Test I08 covers a path traversal attempt using `..` to escape root. Test I09 covers an invalid escape sequence in strict mode. Test I10 covers a file reference to unreadable file for permission errors.

### 8.3 Golden File Format

Each test case shall consist of three files: `{test-id}.hc` containing the input Hypercode, `{test-id}.expected.md` containing the expected Markdown output, and `{test-id}.expected.json` containing the expected manifest. For invalid input tests, the expected files shall contain the expected error message pattern as a regular expression.

-----

## 9. Acceptance Criteria Summary

The implementation shall be accepted when all of the following conditions are met:

All 16 valid input tests produce output matching expected golden files byte-for-byte. All 10 invalid input tests produce appropriate error messages and non-zero exit codes. Cross-platform tests confirm identical behavior on macOS, Linux, and Windows. Performance benchmarks meet or exceed specified thresholds. Code coverage reaches or exceeds 80% for all modules. Documentation is complete including README, language specification, and API docs. The `--help` output accurately describes all arguments and options.

-----

## 10. Future Considerations

The following items are explicitly out of scope for version 0.1 but are anticipated for future versions:

Version 0.2 may introduce Hypercode Cascade Sheets (.hcs) support for configuring embedding modes, selectors for node targeting, and property overrides. Version 0.3 may introduce TaskRecord integration for variable interpolation, YAML frontmatter parsing in task source directories, and dynamic content based on current task context. Version 0.4 may introduce manifest verification mode for validating compiled output against recorded hashes. Version 0.5 may introduce a watch mode for automatic recompilation on source changes.

These future directions should inform architectural decisions in version 0.1, ensuring extensibility without requiring fundamental redesign.

-----

## 11. Glossary of Exit Codes

|Code|Category        |Description                                            |
|----|----------------|-------------------------------------------------------|
|0   |Success         |Compilation completed without errors                   |
|1   |IO Error        |File not found, permission denied, or disk full        |
|2   |Syntax Error    |Invalid Hypercode syntax in source file                |
|3   |Resolution Error|Circular dependency or missing reference in strict mode|
|4   |Internal Error  |Unexpected condition indicating compiler bug           |

-----

## 12. Revision History

|Version|Date      |Author        |Changes            |
|-------|----------|--------------|-------------------|
|0.0.1  |2025-11-25|Egor Merkushev|Initial PRD release|
