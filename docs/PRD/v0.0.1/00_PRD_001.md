# Product Requirements Document: Hyperprompt Compiler v0.1

**Document Version:** 0.0.1
**Date:** November 25, 2025
**Author:** Egor Merkushev
**Status:** Draft for Implementation

-----

## 1. Executive Summary

### 1.1 Objective

The Hyperprompt Compiler v0.1 is a cross‑platform Swift CLI tool that compiles Hypercode (.hc) sources into unified Markdown documents. Version 0.1 implements a minimal, safe, deterministic subset of the Hyperprompt Framework: hierarchical document composition through static, local file embedding with strict provenance guarantees.

This PRD defines **what** the compiler must do, **why**, and the constraints for a correct implementation. It does not prescribe architectural or code‑level solutions (covered in the Design Specification).

### 1.2 Motivation & Context

The Hyperprompt Framework aims to bridge human engineering intent and LLM‑based autonomous agents. Hypercode provides a declarative, indentation‑structured way to describe prompts, documents, workflows, and agent instructions. The compiler is the authoritative way to transform modular Hypercode trees into deterministic Markdown prompts with reproducible provenance.

Key motivations:
- **Deterministic prompting:** LLM‑facing prompts must be reproducible, auditable, and version‑controlled.
- **Safety & traceability:** All embedded content must be validated, hashed, and recorded.
- **Structured composition:** Hypercode provides clarity where free‑form Markdown collapses under complexity.

### 1.3 Primary Deliverables

- A single executable named `hyperprompt`.
- Compiled `.md` output from a root `.hc`.
- A machine‑verifiable JSON manifest with:
  - Hashes (SHA256)
  - File sizes
  - Paths
  - Root reference
  - Compiler version
  - Timestamp

### 1.4 Success Criteria

Successful when the compiler:
- Parses indentation‑based Hypercode.
- Resolves `.md` and `.hc` references; **all other extensions are disallowed**.
- Detects and rejects:
  - Nonexistent files (strict mode)
  - Circular dependencies
  - Path traversal
  - Depth > 10
- Generates correct heading levels or the fallback bold‑text format for deep nodes.
- Produces deterministic output (byte-for-byte stable).
- Generates complete manifest with SHA256 hashes.
- Works unchanged on macOS, Linux, Windows.

### 1.5 Constraints

- UTF‑8 only, no BOM.
- Must not access the network.
- Must not follow symlinks outside root.
- Only `.md` and `.hc` may be embedded. Others → **hard error**.
- Maximum depth: **10**. Depth > 10 → compilation failure.

-----

## 2. Terminology

**Hypercode (.hc):** Indentation‑based declarative structure.

**Literal:** Quoted string.

**File Reference:** Literal resolving to `.md` or `.hc`.

**Inline Text:** Literal not resolving to file.

**Node:** AST element with depth.

**Depth:** Indentation/4.

**Heading Shift:** Adjusted heading level for embedded Markdown.

**Bold Fallback:** For depth >= 6.

**Manifest:** JSON with source file metadata.

**Strict/Lenient modes:** Handling missing references.

-----

## 3. Functional Requirements

### 3.1 Input Processing

#### 3.1.1 Parsing Rules
- Node lines: optional indent (4-space groups) + `"literal"`.
- Tabs forbidden → syntax error.
- Misaligned indentation → error.
- Comments: `#...` after indent.
- Blank lines preserved structurally.
- Literals: must be single-line.

#### 3.1.2 Tree Construction
- Depth = spaces/4.
- Child node attaches to nearest previous node of depth‑1.
- Only one root node allowed (depth 0).
- Depth > 10 → **Resolution Error (exit code 3)**.

### 3.2 Reference Resolution

#### Allowed:
- `.md` — embedded with heading adjustment
- `.hc` — recursively compiled

#### Forbidden:
All other extensions → **hard error (exit code 3)**.

Circular dependencies → resolution error (exit code 3).

Missing files:
- Strict mode → error
- Lenient mode → treated as inline text

### 3.3 Output Generation

#### 3.3.1 Headings
Heading level = depth + 1

If depth >= 6 → use `**Bold Title**` instead of H6.

#### 3.3.2 Embedded Content
- Markdown headings shifted by offset = parentDepth + 1.
- Overflow > H6 → replace with bold text.
- Setext and ATX must both be handled.

### 3.4 Manifest
Generated as `.manifest.json` unless overridden.

Contains:
- timestamp (ISO 8601)
- version
- root
- sources[]
  - path (relative)
  - sha256
  - size
  - type (`markdown` or `hypercode`)

### 3.5 CLI Interface
Required:
- `<input.hc>`

Options:
- `--output, -o`
- `--manifest, -m`
- `--root, -r`
- `--strict` (default)
- `--lenient`
- `--stats`
- `--dry-run`
- `--verbose, -v`
- `--version`
- `--help, -h`

Exit codes: 0..4 (same mapping as original).

-----

## 4. Non‑Functional Requirements

### 4.1 Performance
Soft targets:
- 1000-node tree, avg 4 KB nodes → under ~5 seconds on dev hardware.
- Compiler should scale linearly with file count.
- Output must be deterministic.

### 4.2 Reliability
- No crashes on invalid input.
- Every error must have location + diagnostic.
- **Deterministic output:** All compilation produces byte-for-byte identical output for identical input, regardless of platform or execution order.
  - All output uses LF (Unix-style) line endings
  - Compiled markdown ends with exactly one LF
  - Manifest JSON keys are alphabetically sorted
  - Embedded content normalized to LF before processing

### 4.3 Portability
- macOS Intel/Apple Silicon
- Linux x86_64/arm64
- Windows 10+ x86_64

### 4.4 Maintainability
- >80% code coverage
- Modular boundaries enforced
- Clear diagnostics

### 4.5 Security
- No code execution.
- No symlink escape.
- No traversal (`..`) allowed.

-----

## 5. Hypercode Language Specification

### 5.1 Lexical Structure

A Hypercode source file consists of a sequence of lines and must contain at least one node line. A file may begin with any number of blank lines and comment lines before the first node. Each line is classified as blank, comment, or node. Blank lines contain only space characters (tab characters are not permitted). Comment lines begin with optional indentation (zero or more groups of four spaces) followed by the hash character, then any characters up to the newline. Node lines contain optional leading spaces for indentation, an opening double quotation mark, literal content on a single line, and a closing double quotation mark. Literal content cannot span multiple lines.

### 5.2 Grammar

The formal grammar in extended Backus-Naur form is as follows:

```
program     = { line }, node, { line } ;
line        = blank | comment | node ;
blank       = { space }, newline ;
comment     = [ indent ], "#", { char }, newline ;
node        = [ indent ], '"', content, '"', newline ;
indent      = { "    " } ;
content     = { char } ;
char        = any-char - newline ;
space       = U+0020 ;
newline     = U+000A | U+000D, U+000A ;
any-char    = ? any Unicode scalar value ? ;
```

### 5.3 Semantic Rules

The parser shall skip any blank lines and comment lines at the start of the file until the first node is encountered. This allows files to begin with documentation comments without affecting program validity. After the first node is processed, all lines are processed in order to build the complete tree structure.

Each node's depth is computed as the number of leading spaces divided by four. A node at depth N becomes a child of the most recently encountered node at depth N-1. Only one root node (depth 0) is allowed per file. Additional nodes at depth 0 after the first one result in a syntax error.

The content of each node is interpreted according to resolution rules. If the content matches an existing file path with extension `.md` or `.hc` relative to the root directory, it is treated as a file reference. File references to paths with extension `.hc` are compiled recursively. File references to paths with extension `.md` have their content embedded with heading adjustment. All other file extensions are not supported and result in a resolution error. Otherwise, the content is treated as an inline text literal.

-----

## 6. Architecture

### 6.1 Module Structure

The compiler shall be organized into six primary modules.

The Core module defines fundamental types including SourceLocation, Diagnostic, and CompilerError. It provides utilities for file system access abstraction and string manipulation helpers.

The Parser module implements the Lexer type that performs line-by-line tokenization, the Parser type that constructs the AST from token stream, and the AST types including Node, NodeKind, and Program.

The Resolver module implements the ReferenceResolver type that determines reference types for literals, the DependencyTracker type that detects circular dependencies, and the FileLoader type that reads and caches file contents.

The Emitter module implements the MarkdownEmitter type that generates output from resolved AST, the HeadingAdjuster type that transforms heading levels in embedded content, and the ManifestGenerator type that produces provenance documentation.

The CLI module implements argument parsing using swift-argument-parser, the CompilerDriver type that orchestrates the compilation pipeline, and the DiagnosticPrinter type that formats error messages for terminal output.

The Statistics module implements the StatsCollector type that gathers metrics during compilation and the StatsReporter type that formats statistics for output.

### 6.2 Data Flow

The compilation pipeline proceeds through the following stages. The CLI module parses command-line arguments and validates paths. The Parser module reads the input file, tokenizes lines, and constructs the AST. The Resolver module traverses the AST and resolves each node's content, recursively processing nested Hypercode files and loading Markdown content. The Emitter module traverses the resolved AST and generates Markdown output, adjusting heading levels and inserting separators. The ManifestGenerator module collects metadata from all processed files and produces JSON output. The CLI module writes output files and reports statistics if requested.

### 6.3 Error Handling Strategy

All errors shall be represented as values conforming to the CompilerError protocol, which requires a diagnostic message, an optional source location, and an error category for exit code determination. Functions that may fail shall return Result types rather than throwing exceptions, enabling explicit error propagation and aggregation. The compiler shall attempt to report multiple errors per compilation run where possible, rather than stopping at the first error.

-----

## 7. Implementation Plan

### 7.1 Phase 1: Foundation (A)

**Duration Estimate:** 3 days

This phase establishes the project structure and implements core parsing functionality.

#### Task A1: Project Initialization

Includes creating the Swift package with appropriate directory structure, configuring the Package.swift with dependencies on swift-argument-parser and swift-crypto, establishing the module boundaries, and setting up the test target structure. The priority is high, the effort estimate is 2 hours, and the acceptance criteria is that `swift build` completes without errors and `swift test` runs an empty test suite.

#### Task A2: Implementing Core Types

Includes defining SourceLocation as a struct with file path and line number, defining CompilerError as an enum with associated diagnostic information, implementing the FileSystem protocol for abstracting file operations, and creating a MockFileSystem for testing. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that unit tests verify all error cases produce appropriate diagnostics.

#### Task A3: Implementing the Lexer

Includes implementing line-by-line tokenization, recognizing blank lines, comment lines, and node lines, extracting indentation level and literal content, and enforcing single-line content constraints. The priority is high, the effort estimate is 6 hours, and the acceptance criteria is that lexer correctly tokenizes the provided test corpus of 20 sample files.

#### Task A4: Implementing the Parser

Includes implementing AST node types, building tree structure from token stream based on indentation, computing depth and parent-child relationships, and reporting syntax errors with source locations. The priority is high, the effort estimate is 8 hours, and the acceptance criteria is that parser produces correct AST for all valid test inputs and reports meaningful errors for all invalid inputs.

### 7.2 Phase 2: Resolution (B)

**Duration Estimate:** 4 days

This phase implements file reference resolution and circular dependency detection.

#### Task B1: Implementing the Reference Resolver

Includes implementing file existence checking against the root directory, classifying literals as file references or inline text, handling `.md` and `.hc` extensions differently, and implementing strict and lenient mode behaviors. The priority is high, the effort estimate is 6 hours, and the acceptance criteria is that resolver correctly classifies all reference types in the test corpus.

#### Task B2: Implementing the Dependency Tracker

Includes implementing the visitation stack for cycle detection, detecting direct and transitive circular dependencies, producing clear cycle path descriptions in error messages, and optimizing for deep trees with memoization. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that circular dependencies are detected and reported with full cycle paths.

#### Task B3: Implementing the File Loader

Includes implementing file content reading with encoding detection, caching loaded content to avoid redundant reads, computing SHA256 hashes during loading, and collecting file metadata for manifest generation. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that file content is correctly loaded and cached with accurate hashes.

#### Task B4: Implementing Recursive Compilation

Includes implementing recursive invocation of parser and resolver for `.hc` files, merging child ASTs into parent tree at correct depth, propagating errors from nested compilations, and maintaining consistent source location tracking across files. The priority is high, the effort estimate is 8 hours, and the acceptance criteria is that nested `.hc` files are correctly compiled and embedded.

### 7.3 Phase 3: Emission (C)

**Duration Estimate:** 3 days

This phase implements Markdown output generation.

#### Task C1: Implementing the Heading Adjuster

Includes parsing ATX-style headings with hash prefixes, parsing Setext-style headings with underlines, computing adjusted heading level based on embedding depth, handling overflow beyond H6 with path prefixes, and preserving heading attributes and trailing content. The priority is high, the effort estimate is 6 hours, and the acceptance criteria is that all heading styles are correctly adjusted in test corpus.

#### Task C2: Implementing the Markdown Emitter

Includes implementing tree traversal for output generation, generating headings from node content or file names, embedding file content with adjusted headings, inserting appropriate separators between sections, and handling inline text literals as body content. The priority is high, the effort estimate is 8 hours, and the acceptance criteria is that emitter produces valid Markdown matching expected output for all test cases.

#### Task C3: Implementing the Manifest Generator

Includes collecting metadata from all processed files, generating ISO 8601 timestamp, formatting JSON output with consistent key ordering, and writing manifest to specified path. The priority is medium, the effort estimate is 3 hours, and the acceptance criteria is that manifest contains accurate metadata for all source files.

### 7.4 Phase 4: CLI and Integration (D)

**Duration Estimate:** 3 days

This phase implements the command-line interface and integrates all components.

#### Task D1: Implementing Argument Parsing

Includes defining command structure with swift-argument-parser, implementing all specified flags and options, validating argument combinations, and generating help text. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that all documented arguments are recognized and validated.

#### Task D2: Implementing the Compiler Driver

Includes orchestrating the full compilation pipeline, implementing dry-run mode, implementing verbose logging, and handling interruption signals gracefully. The priority is high, the effort estimate is 6 hours, and the acceptance criteria is that end-to-end compilation succeeds for all valid test inputs.

#### Task D3: Implementing the Diagnostic Printer

Includes formatting error messages with source context, colorizing output for terminal display, supporting plain text output for non-terminal destinations, and aggregating multiple errors when possible. The priority is medium, the effort estimate is 4 hours, and the acceptance criteria is that error messages clearly identify problem location and nature.

#### Task D4: Implementing the Statistics Reporter

Includes collecting metrics during compilation, formatting statistics output, calculating derived metrics such as compression ratio and processing rate, and integrating with verbose mode output. The priority is low, the effort estimate is 3 hours, and the acceptance criteria is that statistics output includes all specified metrics.

### 7.5 Phase 5: Testing and Documentation (E)

**Duration Estimate:** 2 days

This phase completes testing coverage and produces documentation.

#### Task E1: Implementing Integration Tests

Includes creating a test corpus with representative Hypercode files, implementing golden-file tests comparing output to expected results, testing error conditions and edge cases, and achieving 80% code coverage threshold. The priority is high, the effort estimate is 8 hours, and the acceptance criteria is that all integration tests pass and coverage threshold is met.

#### Task E2: Cross-Platform Testing

Includes testing on macOS with both Intel and Apple Silicon, testing on Ubuntu 22.04, testing on Windows 10 with WSL and native, and documenting any platform-specific behaviors. The priority is high, the effort estimate is 4 hours, and the acceptance criteria is that identical inputs produce identical outputs on all platforms.

#### Task E3: Producing Documentation

Includes writing README with installation and usage instructions, documenting the Hypercode language specification, providing example files demonstrating all features, and generating API documentation from source comments. The priority is medium, the effort estimate is 4 hours, and the acceptance criteria is that documentation is complete and accurate.

-----

## 8. Test Corpus Specification

### 8.1 Valid Input Tests

The test corpus shall include the following valid input scenarios.

Test V01 covers a single root node with inline text, verifying basic parsing and emission. Test V03 covers a nested hierarchy three levels deep with inline text. Test V04 covers a single Markdown file reference at root level. Test V05 covers nested Markdown file references at multiple depths. Test V06 covers a single Hypercode file reference. Test V07 covers nested Hypercode file references three levels deep. Test V08 covers mixed inline text and file references at the same depth. Test V09 covers a file reference to Markdown containing headings H1 through H4. Test V10 covers a file reference to Markdown containing Setext-style headings. Test V11 covers comment lines interspersed with nodes. Test V12 covers blank lines between node groups. Test V13 covers the maximum supported depth of 10 levels. Test V14 covers Unicode content in literals and embedded files.

### 8.2 Invalid Input Tests

The test corpus shall include the following invalid input scenarios.

Test I01 covers tab characters in indentation, which should produce a syntax error. Test I02 covers misaligned indentation not divisible by four. Test I03 covers an unclosed quotation mark at end of file. Test I04 covers a missing file reference in strict mode. Test I05 covers a direct circular dependency where A references A. Test I06 covers an indirect circular dependency where A references B, B references A. Test I07 covers a depth exceeding maximum of 10 levels. Test I08 covers a path traversal attempt using `..` to escape root. Test I09 covers a file reference to unreadable file for permission errors. Test I10 covers multiple root nodes (depth 0), which should produce a syntax error.

### 8.3 Golden File Format

Each test case shall consist of three files: `{test-id}.hc` containing the input Hypercode, `{test-id}.expected.md` containing the expected Markdown output, and `{test-id}.expected.json` containing the expected manifest. For invalid input tests, the expected files shall contain the expected error message pattern as a regular expression.

-----

## 9. Acceptance Criteria Summary

- All valid tests match golden files.
- All invalid tests fail predictably.
- Deterministic output on all platforms.
- Manifest accurate.
- Documentation complete.
- Performance within soft limits.

-----

## 10. Future Work

The following items are explicitly out of scope for version 0.1 but are anticipated for future versions:

Version 0.2 may introduce Hypercode Cascade Sheets (.hcs) support for configuring embedding modes, selectors for node targeting, and property overrides. Version 0.3 may introduce TaskRecord integration for variable interpolation, YAML frontmatter parsing in task source directories, and dynamic content based on current task context. Version 0.4 may introduce manifest verification mode for validating compiled output against recorded hashes. Version 0.5 may introduce a watch mode for automatic recompilation on source changes.

These future directions should inform architectural decisions in version 0.1, ensuring extensibility without requiring fundamental redesign.

-----

## 11. Glossary of Exit Codes

|Code|Category        |Description                                            |
|----|----------------|-------------------------------------------------------|
|0   |Success         |Compilation completed without errors                   |
|1   |IO Error        |File not found, permission denied, or disk full        |
|2   |Syntax Error    |Invalid Hypercode syntax in source file                |
|3   |Resolution Error|Circular dependency or missing reference in strict mode|
|4   |Internal Error  |Unexpected condition indicating compiler bug           |

-----

## 12. Revision History

|Version|Date      |Author        |Changes            |
|-------|----------|--------------|-------------------|
|0.0.1  |2025-11-25|Egor Merkushev|Initial PRD release|
